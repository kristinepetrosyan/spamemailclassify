{"cells":[{"metadata":{"_uuid":"e8e2a0c9-b3c2-4059-a4fd-d8844c4fd538","_cell_guid":"93c38f21-a11d-40a6-809c-14f8163667d7","trusted":true},"cell_type":"code","source":"import re\nimport time\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n\n###########################################################################################\n#                            PREPARING DATA FOR PREDICTION                                #\n###########################################################################################\n\n\ndef lemmitize(s):\n    lemmatizer = WordNetLemmatizer()\n    new_s = \"\"\n    for word in s.split(\" \"):\n        lemmatizer.lemmatize(word)\n        if word not in stopwords.words(\"english\"):\n            new_s += word + \" \"\n    return new_s[:-1]\n\n\ndef clean_str(s):\n    # make everything lowercase\n    s = s.lower()\n    # remove urls\n    s = re.sub(re.compile(r\"https?:\\/\\/(www)?.?([A-Za-z_0-9-]+)([\\S])*\"), \"\", s)\n    # remove emails\n    s = re.sub(re.compile(r\"\\S+@\\S+\"), \"\", s)\n    # remove punctuation\n    s = re.sub(re.compile(r\"[^a-z\\s]\"), \"\", s)\n    return s\n\n\ndef prep_data(s):\n    clean_data = clean_str(s)\n    clean_text = lemmitize(clean_data)\n    d = {\"clean_text\": clean_text}\n    return pd.DataFrame([d])\n\n\n\n###########################################################################################\n#                                        MAIN                                             #\n###########################################################################################\n\nif __name__ == \"__main__\":\n    t = time.time()\n    string = \"That somehow managed to be record short yet answer almost all the questions we would've asked, haha! Hi Deb! Welcome to Hou Tian; nice to meet you! I'm Jhenne, one of the mods here-- which means I gotta give you the modly speech :] Make sure to check out the Mandatory Reading up top! Our constantly updated Library is also a great resource, though it isn't mandatory reading-- we like to tell members to 'read as you need', rather than marathon read it all at once. One of the most helpful threads is the Gameplay So Far thread, which breaks down what all has gone down on the boards. (Now, the summary for January isn't tossed up yet, but we'd be happy to break down what you missed if you'd like.) I see that you're interested in Mai! That means both the Trying for a Canon Character page, and the Canon Character Rules and Consequences post will be helpful to check out. If you're ever considering an original character, we have our player-made adoptables list, and our factions, comprised of the Jade Shark/Bending Opposition, Original People of the Flame, and The Bending Crime Syndicates. As far as characters go, in the past tense I play Srai, a Jade Shark [s]that is very very dusty. In the Korraverse I play a reporter named Chihiro, and an ex-taxi dancer/wannabe actress named Naoki, and a Republic City University student named Haruna. I think that's it! If you have any questions, don't hesitate to ask a mod, or drop it right here in this thread so we can get back to you! Again, welcome! #CONFETTI\"\n    print(string)\n    print(prep_data(string))\n    print(f\"Preprocessing Time: {time.time() - t} seconds\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}